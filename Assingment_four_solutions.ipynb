{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T03:40:41.498500Z",
     "start_time": "2025-11-19T03:39:28.748993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Base URL\n",
    "BASE_URL = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "\n",
    "# Data storage\n",
    "books_data = []\n",
    "\n",
    "# Loop through all 50 pages\n",
    "for page in range(1, 51):\n",
    "    url = BASE_URL.format(page)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # If page does not exist, stop scraping\n",
    "    if response.status_code != 200:\n",
    "        break\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find all book containers\n",
    "    books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "\n",
    "    for book in books:\n",
    "        # Title\n",
    "        title = book.h3.a[\"title\"]\n",
    "\n",
    "        # Price\n",
    "        price = book.find(\"p\", class_=\"price_color\").text.strip()\n",
    "\n",
    "        # Availability\n",
    "        availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
    "\n",
    "        # Star Rating (class has \"star-rating Three\", etc.)\n",
    "        star_class = book.find(\"p\")[\"class\"]\n",
    "        star_rating = star_class[1] if len(star_class) > 1 else \"No Rating\"\n",
    "\n",
    "        books_data.append([title, price, availability, star_rating])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(books_data, columns=[\"Title\", \"Price\", \"Availability\", \"Star Rating\"])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"books.csv\", index=False)\n",
    "\n",
    "print(\"✅ Scraping complete! Data saved to books.csv\")\n"
   ],
   "id": "645e2a1a9dc08285",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scraping complete! Data saved to books.csv\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T03:37:57.760077Z",
     "start_time": "2025-11-19T03:37:35.771337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# --- 1. Setup Selenium with Anti-Detection & Auto-Driver ---\n",
    "options = Options()\n",
    "# options.add_argument('--headless')  # Keep commented out to see the browser working\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "# Automatically download and install the correct Chrome driver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "movies_data = []\n",
    "\n",
    "try:\n",
    "    # --- 2. Access the Website ---\n",
    "    url = \"https://www.imdb.com/chart/top/\"\n",
    "    print(\"Accessing IMDB Top 250...\")\n",
    "    driver.get(url)\n",
    "\n",
    "    # --- 3. Wait for Data to Load ---\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    # Wait until the movie list items are present in the DOM\n",
    "    movie_elements = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"li.ipc-metadata-list-summary-item\")))\n",
    "\n",
    "    print(f\"Found {len(movie_elements)} movies. Starting extraction...\")\n",
    "\n",
    "    # --- 4. Extract Data Loop ---\n",
    "    for movie in movie_elements:\n",
    "        try:\n",
    "            # A. Extract Title & Rank\n",
    "            # The title is inside an h3 tag, e.g., \"1. The Shawshank Redemption\"\n",
    "            title_element = movie.find_element(By.CSS_SELECTOR, \"h3.ipc-title__text\")\n",
    "            full_text = title_element.text\n",
    "\n",
    "            # Split Rank and Title\n",
    "            if \". \" in full_text:\n",
    "                rank, title = full_text.split(\". \", 1)\n",
    "            else:\n",
    "                rank = \"N/A\"\n",
    "                title = full_text\n",
    "\n",
    "            # B. Extract Metadata (Year, Duration, Rated)\n",
    "            # The year is usually the first span inside the metadata container\n",
    "            metadata_items = movie.find_elements(By.CSS_SELECTOR, \"div.cli-title-metadata span\")\n",
    "            year = metadata_items[0].text if metadata_items else \"N/A\"\n",
    "\n",
    "            # C. Extract Rating\n",
    "            # The rating is inside a span with a specific class, e.g., \"9.3 (2.8M)\"\n",
    "            rating_element = movie.find_element(By.CSS_SELECTOR, \"span.ipc-rating-star\")\n",
    "            # We split by space to get just the number \"9.3\"\n",
    "            rating = rating_element.text.split()[0]\n",
    "\n",
    "            # Append to list\n",
    "            movies_data.append({\n",
    "                \"Rank\": rank,\n",
    "                \"Movie Title\": title,\n",
    "                \"Year of Release\": year,\n",
    "                \"IMDB Rating\": rating\n",
    "            })\n",
    "\n",
    "            # Stop if we have enough (optional safety check)\n",
    "            if len(movies_data) >= 250:\n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            # If a single movie fails, print error but continue to the next one\n",
    "            # print(f\"Skipping a movie due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    # --- 5. Save Data to CSV ---\n",
    "    if movies_data:\n",
    "        df_imdb = pd.DataFrame(movies_data)\n",
    "        df_imdb.to_csv('imdb_top250.csv', index=False)\n",
    "        print(f\"Success! {len(df_imdb)} movies saved to 'imdb_top250.csv'.\")\n",
    "    else:\n",
    "        print(\"Failed to extract any movie data.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()"
   ],
   "id": "77f00c38fc79080a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing IMDB Top 250...\n",
      "Found 250 movies. Starting extraction...\n",
      "Success! 250 movies saved to 'imdb_top250.csv'.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T03:41:39.755360Z",
     "start_time": "2025-11-19T03:41:39.585038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "URL = \"https://www.timeanddate.com/weather/\"\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"}\n",
    "\n",
    "resp = requests.get(URL, headers=HEADERS, timeout=15)\n",
    "resp.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "# Pick the first <table> that contains a degree symbol — likely the weather table\n",
    "table = next((t for t in soup.find_all(\"table\") if \"°\" in t.get_text()), None)\n",
    "if table is None:\n",
    "    raise SystemExit(\"Could not find the weather table. Page layout may have changed.\")\n",
    "\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "records = []\n",
    "for tr in rows:\n",
    "    text = tr.get_text(\" \", strip=True)\n",
    "    if \"°\" not in text:           # skip non-weather rows\n",
    "        continue\n",
    "\n",
    "    # City: first <a> text in the row (fallback to first cell text)\n",
    "    a = tr.find(\"a\")\n",
    "    city = a.get_text(strip=True) if a else (tr.find(\"td\").get_text(strip=True) if tr.find(\"td\") else \"\")\n",
    "\n",
    "    # Temperature: find e.g. 24 °C or 24°C\n",
    "    temp_match = re.search(r\"(-?\\d+)\\s*°\\s*([CF])\", text, flags=re.I)\n",
    "    temperature = f\"{temp_match.group(1)} °{temp_match.group(2).upper()}\" if temp_match else \"\"\n",
    "\n",
    "    # Condition: prefer icon alt text, else look for common words\n",
    "    img = tr.find(\"img\", alt=True)\n",
    "    if img and img[\"alt\"].strip():\n",
    "        condition = img[\"alt\"].strip()\n",
    "    else:\n",
    "        cond_match = re.search(r\"\\b(Clear|Cloudy|Sunny|Rain|Showers|Snow|Mist|Fog|Overcast|Thunder|Windy)\\b\", text, flags=re.I)\n",
    "        condition = cond_match.group(0) if cond_match else \"\"\n",
    "\n",
    "    records.append({\"City Name\": city, \"Temperature\": temperature, \"Weather Condition\": condition})\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df = df[df[\"City Name\"].astype(bool)]   # drop any rows without a city name\n",
    "\n",
    "print(f\"Found {len(df)} rows. Sample:\")\n",
    "print(df.head(10).to_string(index=False))\n",
    "\n",
    "df.to_csv(\"weather.csv\", index=False)\n",
    "print(\"Saved to weather.csv\")\n"
   ],
   "id": "e69b3e310b1318d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 71 rows. Sample:\n",
      "  City Name Temperature           Weather Condition\n",
      "      Accra       27 °C       Passing clouds. Warm.\n",
      "Addis Ababa       10 °C       Passing clouds. Cool.\n",
      "   Adelaide       18 °C                       Cool.\n",
      "    Algiers       17 °C       Passing clouds. Mild.\n",
      "     Almaty        4 °C                Fog. Chilly.\n",
      "      Amman       11 °C                Clear. Cool.\n",
      "  Amsterdam        6 °C Passing clouds. Quite cool.\n",
      "     Anadyr      -24 °C      Sunny. Extremely cold.\n",
      "  Anchorage       -3 °C      Mostly cloudy. Chilly.\n",
      "     Ankara        2 °C              Clear. Chilly.\n",
      "Saved to weather.csv\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
