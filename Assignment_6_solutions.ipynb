{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** (Gaussian Naïve Bayes Classifier) Implement Gaussian Naïve Bayes Classifier on the Iris dataset from sklearn.datasets using (i) Step-by-step implementation (ii) In-built function"
      ],
      "metadata": {
        "id": "7fCvCz8hG3zj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsq3UHDlGU0h",
        "outputId": "68aa1758-0057-4e32-966f-fb6bbc8c2207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step-by-Step Implementation Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load and Split Data\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. Training: Calculate Mean and Std Dev for each class\n",
        "classes = np.unique(y_train)\n",
        "mean_var = {}\n",
        "\n",
        "for c in classes:\n",
        "    # Filter data for the current class\n",
        "    X_c = X_train[y_train == c]\n",
        "    # Store mean and variance for each feature (column)\n",
        "    mean_var[c] = {\n",
        "        'mean': X_c.mean(axis=0),\n",
        "        'var': X_c.var(axis=0)\n",
        "    }\n",
        "\n",
        "# 3. Helper function: Gaussian Probability Density\n",
        "def calculate_probability(x, mean, var):\n",
        "    exponent = np.exp(-((x - mean) ** 2) / (2 * var))\n",
        "    return (1 / np.sqrt(2 * np.pi * var)) * exponent\n",
        "\n",
        "# 4. Prediction Step\n",
        "y_pred = []\n",
        "for x in X_test:\n",
        "    posteriors = []\n",
        "    for c in classes:\n",
        "        # Get stored stats for class c\n",
        "        mean = mean_var[c]['mean']\n",
        "        var = mean_var[c]['var']\n",
        "\n",
        "        # Calculate Prior (P(Class)) - assumed equal or proportional\n",
        "        prior = np.log(len(X_train[y_train == c]) / len(X_train))\n",
        "\n",
        "        # Calculate Likelihood (P(Data|Class))\n",
        "        # We sum logs to avoid underflow issues (Log Likelihood)\n",
        "        likelihood = np.sum(np.log(calculate_probability(x, mean, var)))\n",
        "\n",
        "        # Posterior = Prior + Likelihood (in log scale)\n",
        "        posteriors.append(prior + likelihood)\n",
        "\n",
        "    # Select class with highest posterior probability\n",
        "    y_pred.append(classes[np.argmax(posteriors)])\n",
        "\n",
        "# 5. Evaluation\n",
        "print(\"Step-by-Step Implementation Accuracy:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load Data\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# 2. Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Train Model\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Predict and Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"In-built Implementation Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y3WTB9YGey8",
        "outputId": "d07a0f0f-1cdb-4b2d-ed13-cbb1cb0a291c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In-built Implementation Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Explore about GridSearchCV toot in scikit-learn. This is a tool that is\n",
        "often used for tuning hyperparameters of machine learning models. Use\n",
        "this tool to find the best value of K for K-NN Classifier using any dataset"
      ],
      "metadata": {
        "id": "x7gocnrTG7o5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# 1. Load Data\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# 2. Split Data (Optional for GridSearch, but good practice to keep a hold-out set)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 3. Setup GridSearchCV\n",
        "# Define the model\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Define the parameter grid: Test K from 1 to 30\n",
        "param_grid = {'n_neighbors': list(range(1, 31))}\n",
        "\n",
        "# Initialize GridSearch\n",
        "# cv=5 means 5-fold Cross-Validation\n",
        "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# 4. Run the search on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 5. Results\n",
        "print(\"Best Value for K:\", grid_search.best_params_['n_neighbors'])\n",
        "print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
        "\n",
        "# Optional: Validate on the test set with the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Test Set Accuracy with Best K:\", best_model.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeSMDwjOGiUR",
        "outputId": "36ee2020-3aad-4fc1-8666-31eb6569e922"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Value for K: 3\n",
            "Best Cross-Validation Score: 0.9583333333333334\n",
            "Test Set Accuracy with Best K: 1.0\n"
          ]
        }
      ]
    }
  ]
}